{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmojiPred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas\n",
    "import string\n",
    "import pandas as pd\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle \n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 03:49:36.036582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 13439 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Tensorflow GPU check\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = 'embeddings/twitter_27B_200d.kv'\n",
    "embed_dim = 200\n",
    "emb_model = KeyedVectors.load(embed_path)\n",
    "\n",
    "# backtranslated data\n",
    "lang = 'hindi'\n",
    "label_map = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 9:9, 10:10, 12:11, 13:12, 14:13, 15:14, 16:15, 17:16, 18:17, 19:18}\n",
    "data_path = 'data/indian-langs/hindi_tweets_translated.csv'\n",
    "min_len = 2\n",
    "max_len = 15\n",
    "max_pad_len = 10\n",
    "num_classes = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the village weather pink in your files but the...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is well terimerikhani a stone heart to bring t...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shri hanuman jnmotswacya hardik goodwill anjan...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>does not care in this scorching sun greenery i...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeh amar ujala hai that immortal dark news hey...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  the village weather pink in your files but the...     13\n",
       "1  is well terimerikhani a stone heart to bring t...      7\n",
       "2  shri hanuman jnmotswacya hardik goodwill anjan...     12\n",
       "3  does not care in this scorching sun greenery i...      6\n",
       "4  yeh amar ujala hai that immortal dark news hey...     14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " tweet    459\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "After:\n",
      " tweet    0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\\n\", df.isnull().sum())\n",
    "df = df.dropna()\n",
    "print(\"\\nAfter:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    word_list = []\n",
    "    for i in text.split():\n",
    "        if i not in stopwords.words('english'):\n",
    "            word_list.append(i)\n",
    "    text_clean = \" \".join(word_list)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>village weather pink files figures false claim...</td>\n",
       "      <td>12</td>\n",
       "      <td>[village, weather, pink, files, figures, false...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well terimerikhani stone heart bring two live ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[well, terimerikhani, stone, heart, bring, two...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shri hanuman jnmotswacya hardik goodwill anjan...</td>\n",
       "      <td>11</td>\n",
       "      <td>[shri, hanuman, jnmotswacya, hardik, goodwill,...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>care scorching sun greenery smelling skeletons...</td>\n",
       "      <td>6</td>\n",
       "      <td>[care, scorching, sun, greenery, smelling, ske...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeh amar ujala hai immortal dark news hey ance...</td>\n",
       "      <td>13</td>\n",
       "      <td>[yeh, amar, ujala, hai, immortal, dark, news, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  \\\n",
       "0  village weather pink files figures false claim...     12   \n",
       "1  well terimerikhani stone heart bring two live ...      7   \n",
       "2  shri hanuman jnmotswacya hardik goodwill anjan...     11   \n",
       "3  care scorching sun greenery smelling skeletons...      6   \n",
       "4  yeh amar ujala hai immortal dark news hey ance...     13   \n",
       "\n",
       "                                               token  len  \n",
       "0  [village, weather, pink, files, figures, false...    8  \n",
       "1  [well, terimerikhani, stone, heart, bring, two...    8  \n",
       "2  [shri, hanuman, jnmotswacya, hardik, goodwill,...   16  \n",
       "3  [care, scorching, sun, greenery, smelling, ske...    8  \n",
       "4  [yeh, amar, ujala, hai, immortal, dark, news, ...   16  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token'] = df['tweet'].apply(lambda x: x.split())\n",
    "df['len'] = df['token'].apply(lambda x: len(x))\n",
    "df['label'] = df['label'].apply(lambda x: label_map[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18] \n",
      " 19\n"
     ]
    }
   ],
   "source": [
    "temp = sorted(df['label'].value_counts().index)\n",
    "print(temp, \"\\n\", len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    6157\n",
       "9     5935\n",
       "11    5667\n",
       "8     5392\n",
       "12    5376\n",
       "13    4607\n",
       "7     4194\n",
       "14    3772\n",
       "15    2905\n",
       "6     2782\n",
       "16    2103\n",
       "5     1824\n",
       "17    1513\n",
       "4     1145\n",
       "18    1037\n",
       "19     825\n",
       "3      781\n",
       "20     608\n",
       "2      586\n",
       "21     466\n",
       "1      452\n",
       "22     353\n",
       "23     262\n",
       "24     212\n",
       "25     104\n",
       "0       95\n",
       "26      79\n",
       "27      48\n",
       "28      30\n",
       "29      15\n",
       "30      12\n",
       "32      11\n",
       "31       9\n",
       "35       9\n",
       "34       3\n",
       "37       2\n",
       "40       2\n",
       "62       1\n",
       "42       1\n",
       "33       1\n",
       "39       1\n",
       "71       1\n",
       "58       1\n",
       "46       1\n",
       "Name: len, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='len', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAE9CAYAAAA1R8WUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjBElEQVR4nO3de7hcdX3v8fcXAih4AWSDmGDDqVGLPRVpithaa6GFgByCcikeLxHxiaVgxV6hF1GoLdZWvBxFKQSDN0QikCICKWrtOUeBRC4GIhIVCpFLNIBaHvGA3/PH+m0YwlzW2tm/7Ozk/XqeefZaa9Z3fr+Z+c2az16zZk1kJpIkSZIm11ZT3QFJkiRpc2TQliRJkiowaEuSJEkVGLQlSZKkCgzakiRJUgUGbUmSJKmCGVPdgRp22WWXnD179lR3Q5IkSZu5FStW/DAzx/pdt1kG7dmzZ7N8+fKp7oYkSZI2cxFxx6DrPHREkiRJqsCgLUmSJFVg0JYkSZIqMGhLkiRJFRi0JUmSpAoM2pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKpgx1R2QpqvFnziw0/oL3nRVpZ5IkqRNkXu0JUmSpAoM2pIkSVIFVYN2ROwYERdFxLcjYlVEvCwido6IZRFxW/m7U1k3IuJDEbE6Im6KiH16bmdBWf+2iFhQs8+SJEnSZKi9R/uDwBWZ+ULgxcAq4GTg6sycA1xd5gEOBuaUy0LgLICI2Bk4FXgpsC9w6ng4lyRJkjZV1YJ2RDwTeAVwLkBm/jwzHwDmA4vLaouBw8v0fOD8bHwD2DEidgcOApZl5rrMvB9YBsyr1W9JkiRpMtTco70nsBY4LyKuj4hzImIHYLfMvLuscw+wW5meCdzZU39XWTZouSRJkrTJqhm0ZwD7AGdl5kuA/+Lxw0QAyMwEcjIai4iFEbE8IpavXbt2Mm5SkiRJmrCaQfsu4K7MvKbMX0QTvO8th4RQ/t5Xrl8D7NFTP6ssG7T8CTLz7Mycm5lzx8bGJvWOSJIkSV1V+8GazLwnIu6MiBdk5q3AAcAt5bIAOKP8vbSULAVOjIgLaL74+GBm3h0RVwJ/3/MFyAOBU2r1W1uWz5/X7XD/o469olJPJEnS5qb2L0O+Dfh0RGwLfA84lmYv+oURcRxwB3B0Wfdy4BBgNfBQWZfMXBcRpwPXlfVOy8x1lfstSZIkbZCqQTszbwDm9rnqgD7rJnDCgNtZBCya1M5JkiRJFfnLkJIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBbV/gl1SHx//5EGd1n/rG66s1BNJklSLe7QlSZKkCgzakiRJUgUGbUmSJKkCg7YkSZJUgUFbkiRJqsCgLUmSJFVg0JYkSZIqMGhLkiRJFRi0JUmSpAoM2pIkSVIF/gS7pr3LFh3caf1D3/ylSj2RJEl6nEFbmmbO/MxBnWve8T+vrNATSZI0jIeOSJIkSRUYtCVJkqQKDNqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVGLQlSZKkCgzakiRJUgVVg3ZE3B4R34qIGyJieVm2c0Qsi4jbyt+dyvKIiA9FxOqIuCki9um5nQVl/dsiYkHNPkuSJEmTYWPs0f7dzNw7M+eW+ZOBqzNzDnB1mQc4GJhTLguBs6AJ5sCpwEuBfYFTx8O5JEmStKmaikNH5gOLy/Ri4PCe5edn4xvAjhGxO3AQsCwz12Xm/cAyYN5G7rMkSZLUSe2gncBVEbEiIhaWZbtl5t1l+h5gtzI9E7izp/ausmzQckmSJGmTNaPy7b88M9dExK7Asoj4du+VmZkRkZPRUAnyCwGe+9znTsZNSpIkSRNWdY92Zq4pf+8DLqY5xvreckgI5e99ZfU1wB495bPKskHL12/r7Mycm5lzx8bGJvuuSJIkSZ1UC9oRsUNEPH18GjgQWAksBcbPHLIAuLRMLwXeWM4+sh/wYDnE5ErgwIjYqXwJ8sCyTJIkSdpk1Tx0ZDfg4ogYb+czmXlFRFwHXBgRxwF3AEeX9S8HDgFWAw8BxwJk5rqIOB24rqx3Wmauq9hvSZIkaYNVC9qZ+T3gxX2W/wg4oM/yBE4YcFuLgEWT3UdJkiSpFn8ZUpIkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVWDQliRJkiqYMdUdkLRxnf65gzqt/7d/cGWlnkiStHlzj7YkSZJUgUFbkiRJqsCgLUmSJFVg0JYkSZIqMGhLkiRJFRi0JUmSpAoM2pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBQZtSZIkqYIZU90B6epzXtW55oC3fLFCTyRJkiaPe7QlSZKkCgzakiRJUgUGbUmSJKkCg7YkSZJUQfWgHRFbR8T1EXFZmd8zIq6JiNUR8bmI2LYs367Mry7Xz+65jVPK8lsj4qDafZYkSZI21MbYo/12YFXP/HuBMzPzecD9wHFl+XHA/WX5mWU9ImIv4BjgRcA84KMRsfVG6LckSZI0YVWDdkTMAl4FnFPmA9gfuKisshg4vEzPL/OU6w8o688HLsjMhzPz+8BqYN+a/ZYkSZI2VO092h8A/gL4RZl/FvBAZj5S5u8CZpbpmcCdAOX6B8v6jy3vUyNJkiRtkqoF7Yg4FLgvM1fUamO99hZGxPKIWL527dqN0aQkSZI0UM092r8FHBYRtwMX0Bwy8kFgx4gY/0XKWcCaMr0G2AOgXP9M4Ee9y/vUPCYzz87MuZk5d2xsbPLvjSRJktRBtaCdmadk5qzMnE3zZcYvZ+brgK8AR5bVFgCXlumlZZ5y/ZczM8vyY8pZSfYE5gDX1uq3JEmSNBlmjF5l0v0lcEFE/B1wPXBuWX4u8MmIWA2sownnZObNEXEhcAvwCHBCZj668bstSZIktbdRgnZmfhX4apn+Hn3OGpKZPwOOGlD/HuA99XooSZIkTS5/GVKSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVTMVZRyRNU3+yZF6n9d9/xBWVeiJJ0qbPPdqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVGLQlSZKkCgzakiRJUgUGbUmSJKmCVkE7Iq5us0ySJElSY8awKyPiKcD2wC4RsRMQ5apnADMr902SJEmatoYGbeCtwEnAc4AVPB60fwz8r3rdkiRJkqa3oUE7Mz8IfDAi3paZH95IfZIkSZKmvVF7tAHIzA9HxG8Cs3trMvP8Sv2SJEmSprVWQTsiPgn8MnAD8GhZnIBBW5IkSeqjVdAG5gJ7ZWbW7IwkSZK0uWh7Hu2VwLNrdkSSJEnanLTdo70LcEtEXAs8PL4wMw+r0itJkiRpmmsbtN9VsxOSJEnS5qbtWUf+vXZHJEmSpM1J27OO/ITmLCMA2wLbAP+Vmc+o1TFJkiRpOmu7R/vp49MREcB8YL9anZIkSZKmu7ZnHXlMNi4BDpr87kiSJEmbh7aHjrymZ3YrmvNq/6xKjyRJkqTNQNuzjvyPnulHgNtpDh+RJEmS1EfbY7SPrd0RSZIkaXPS6hjtiJgVERdHxH3lsiQiZtXunCRJkjRdtf0y5HnAUuA55fKvZdlAEfGUiLg2Im6MiJsj4t1l+Z4RcU1ErI6Iz0XEtmX5dmV+dbl+ds9tnVKW3xoRfglTkiRJm7y2QXssM8/LzEfK5RPA2Iiah4H9M/PFwN7AvIjYD3gvcGZmPg+4HziurH8ccH9ZfmZZj4jYCzgGeBEwD/hoRGzd9g5KkiRJU6Ft0P5RRLw+IrYul9cDPxpWUE4D+NMyu025JLA/cFFZvhg4vEzPL/OU6w/oOWf3BZn5cGZ+H1gN7Nuy35IkSdKUaBu03wwcDdwD3A0cCbxpVFEJ5TcA9wHLgO8CD2TmI2WVu4CZZXomcCdAuf5B4Fm9y/vUSJIkSZuktkH7NGBBZo5l5q40wfvdo4oy89HM3BuYRbMX+oUT7egoEbEwIpZHxPK1a9fWakaSJElqpW3Q/rXMvH98JjPXAS9p20hmPgB8BXgZsGNEjJ9WcBawpkyvAfYAKNc/k+bwlMeW96npbePszJybmXPHxkYdPi5JkiTV1TZobxURO43PRMTOjDgHd0SMRcSOZfqpwO8Dq2gC95FltQXApWV6aZmnXP/lzMyy/JhyVpI9gTnAtS37LUmSJE2Jtr8M+c/A1yPi82X+KOA9I2p2BxaXM4RsBVyYmZdFxC3ABRHxd8D1wLll/XOBT0bEamAdzZlGyMybI+JC4BaaX6U8ITMfbdlvSZIkaUq0/WXI8yNiOc0ZQwBek5m3jKi5iT6Hl2Tm9+hz1pDM/BlNgO93W+9hdLCXtAk78tJ5nda/aP4VlXoiSdLG0XaPNiVYDw3XkiRJkhptj9GWJEmS1IFBW5IkSarAoC1JkiRV0PoYbWmY/3v2oZ3W/82Fl1XqiSRJ0qbBPdqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVGLQlSZKkCgzakiRJUgUGbUmSJKkCg7YkSZJUgUFbkiRJqsCgLUmSJFVg0JYkSZIqMGhLkiRJFRi0JUmSpAoM2pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBQZtSZIkqQKDtiRJklTBjKnugCSNcvClf9i55kvzP1ahJ5IktVdtj3ZE7BERX4mIWyLi5oh4e1m+c0Qsi4jbyt+dyvKIiA9FxOqIuCki9um5rQVl/dsiYkGtPkuSJEmTpeahI48Af5qZewH7ASdExF7AycDVmTkHuLrMAxwMzCmXhcBZ0ARz4FTgpcC+wKnj4VySJEnaVFUL2pl5d2Z+s0z/BFgFzATmA4vLaouBw8v0fOD8bHwD2DEidgcOApZl5rrMvB9YBsyr1W9JkiRpMmyUL0NGxGzgJcA1wG6ZeXe56h5gtzI9E7izp+yusmzQckmSJGmTVT1oR8TTgCXASZn5497rMjOBnKR2FkbE8ohYvnbt2sm4SUmSJGnCqgbtiNiGJmR/OjO/UBbfWw4Jofy9ryxfA+zRUz6rLBu0/Aky8+zMnJuZc8fGxib3jkiSJEkd1TzrSADnAqsy8/09Vy0Fxs8csgC4tGf5G8vZR/YDHiyHmFwJHBgRO5UvQR5YlkmSJEmbrJrn0f4t4A3AtyLihrLsr4AzgAsj4jjgDuDoct3lwCHAauAh4FiAzFwXEacD15X1TsvMdRX7LUmSJG2wakE7M/83EAOuPqDP+gmcMOC2FgGLJq93kiRJUl3+BLskSZJUgUFbkiRJqqDmMdqaZm4867BO67/4+KWVeiJJkjT9uUdbkiRJqsCgLUmSJFVg0JYkSZIqMGhLkiRJFRi0JUmSpAoM2pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRXMmOoOSFJth1zyN53Wv/zwv6vUE0nSlsQ92pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JkiRVYNCWJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVzJjqDmhyfffD8zut/8tvu7RSTyRJkrZs7tGWJEmSKqgWtCNiUUTcFxEre5btHBHLIuK28nensjwi4kMRsToiboqIfXpqFpT1b4uIBbX6K0mSJE2mmnu0PwHMW2/ZycDVmTkHuLrMAxwMzCmXhcBZ0ARz4FTgpcC+wKnj4VySJEnalFU7RjszvxYRs9dbPB94ZZleDHwV+Muy/PzMTOAbEbFjROxe1l2WmesAImIZTXj/bK1+S1KvQy4+o9P6l7/65NErSZK2CBv7GO3dMvPuMn0PsFuZngnc2bPeXWXZoOWSJEnSJm3KvgxZ9l7nZN1eRCyMiOURsXzt2rWTdbOSJEnShGzsoH1vOSSE8ve+snwNsEfPerPKskHLnyQzz87MuZk5d2xsbNI7LkmSJHWxsYP2UmD8zCELgEt7lr+xnH1kP+DBcojJlcCBEbFT+RLkgWWZJEmStEmr9mXIiPgszZcZd4mIu2jOHnIGcGFEHAfcARxdVr8cOARYDTwEHAuQmesi4nTgurLeaeNfjJQkSZI2ZTXPOvLaAVcd0GfdBE4YcDuLgEWT2DVJkiSpOn8ZUpIkSarAoC1JkiRVUO3QEUna0r3qCx/stP4XX/P2Sj2RJE0F92hLkiRJFbhHexP0g4+c1Gn955zwgSr9kCRJ0sS5R1uSJEmqwKAtSZIkVWDQliRJkiowaEuSJEkVGLQlSZKkCgzakiRJUgWe3k+SNkGvWvLxTut/8Yi3VuqJJGmiDNoV3HvWGZ3W3+34kyv1RJIkSVPFQ0ckSZKkCgzakiRJUgUGbUmSJKkCg7YkSZJUgV+GlKTNzKFLzutcc9kRx1boiSRt2QzaA6z9WLdTa439oafWkiRJ0uM8dESSJEmqwKAtSZIkVWDQliRJkirwGG1J0hMcetGnO61/2ZGvq9QTSZre3KMtSZIkVWDQliRJkiowaEuSJEkVeIy2JGnSHHrR5zutf9mRR1XqiSRNPfdoS5IkSRW4R1uStEk47KJLO62/9Mj5lXoiSZPDPdqSJElSBQZtSZIkqQKDtiRJklSBx2hLkqa9+Rdd0Wn9S4+cV6knkvS4aRO0I2Ie8EFga+CczDxjVM3asz7VqY2x418/sc5Jkqa1Vy/5aqf1Lz7ilVX6IWnzMi0OHYmIrYGPAAcDewGvjYi9prZXkiRJ0mDTZY/2vsDqzPweQERcAMwHbpnSXkmStnhHLLmm0/pLjnhppZ5I2tRMl6A9E7izZ/4uwC2VJGlaO2rJyk7rf/6IX31sesEX7uhUu/g1v/TY9OkX/6BTLcDfvvo5j01//Av3dap962t2fWz6wiU/7FR79BG7dFq/hhXndru/AL9+3K6jV9JmLzJzqvswUkQcCczLzLeU+TcAL83ME3vWWQgsLLMvAG4dcpO7AN1e6VNfO5VtT8faqWzb+zw9aqeybe/z9KidyranY+1Utu19nh61U9l2zdpfysyxvtdk5iZ/AV4GXNkzfwpwygbc3vLpVjtd++3j5X3eVGuna7+9zz5em2rtdO2399nHq2bttPgyJHAdMCci9oyIbYFjgKVT3CdJkiRpoGlxjHZmPhIRJwJX0pzeb1Fm3jzF3ZIkSZIGmhZBGyAzLwcun6SbO3sa1k5l29Oxdirb9j5Pj9qpbNv7PD1qp7Lt6Vg7lW17n6dH7VS2PSW10+LLkJIkSdJ0M12O0ZYkSZKmlS0qaEfEvIi4NSJWR8TJHWsXRcR9EdHtpKdN7R4R8ZWIuCUibo6It3eofUpEXBsRN5bad0+g/a0j4vqIuGwCtbdHxLci4oaIWN6xdseIuCgivh0RqyLiZS3rXlDaG7/8OCJO6tDuO8pjtTIiPhsRT+lQ+/ZSd3ObNvuNi4jYOSKWRcRt5e9OHWqPKm3/IiLmdmz3feWxvikiLo6IHTvWn15qb4iIqyLiOW1re67704jIiOh74tsB7b4rItb0PN+HdGk3It5W7vfNEfGPHdr9XE+bt0fEDf1qh9TvHRHfGH9tRMS+HWpfHBFfL6+tf42IZwyo7bvtaDPGhtSOHGNDakeOsSG1bcfX0O3lsDE2pO2RY2xYu6PG2JB2R46xIbVtx9eg+pFjLAa8v0Rz4oFronmv/Fw0JyFoW3tiqRu2HRhU++lo3qNXRvO62aZj/bll2U3RvPc8rW1tz/Ufioifdmz3ExHx/Z7neu8Otf/RU/eDiLikQ+3+EfHN8ngtjoiBhwPHejmgzXM8or7VczWgNiLiPRHxnWiywR8PqHtS/oj2r4sn5Y9o+R4ZAzJItHx/fpINOUXLdLrQfInyu8B/A7YFbgT26lD/CmAfYOUE2t4d2KdMPx34Ttu2gQCeVqa3Aa4B9uvY/p8AnwEum0Dfbwd2meBjvhh4S5neFthxgs/bPTTnqGyz/kzg+8BTy/yFwJta1v4qsBLYnub7C/8GPK/ruAD+ETi5TJ8MvLdD7a/QnAf+q8Dcju0eCMwo0+8d1O6Q+mf0TP8x8LG2tWX5HjRfWL5j0JgZ0O67gD9r8fz0q/3d8jxtV+Z37dLnnuv/GXhnx7avAg4u04cAX+1Qex3wO2X6zcDpA2r7bjvajLEhtSPH2JDakWNsSG3b8TVwezlqjA1pe+QYG1I7cowN6/OoMTak3bbja1D9yDHGgPcXmu3mMWX5x4DjO9S+BJjNkPeOIbWHlOsC+Gy/dkfU946x91NeI21qy/xc4JPATzu2+wngyBHja+R7ObAEeGPL2t+k+SG/55flpwHHDWn/CTmgzXM8or7VczWg9ljgfGCrQa+psvxJY4j2r4sn5Q86vEf23M5jGYSW78/rX7akPdqP/Yx7Zv4cGP8Z91Yy82vAuok0nJl3Z+Y3y/RPgFU0gbBNbWbm+H/X25RL6wPrI2IW8CrgnE6d3kAR8UyagHEuQGb+PDMfmMBNHQB8NzO7/ATaDOCp5b/77YG2P4H2K8A1mflQZj4C/DvwmmEFA8bFfJoXOeXv4W1rM3NVZg77saVhtVeVfgN8A5jVsf7HPbM7MGCcDXktnAn8xaC6EbUjDag9HjgjMx8u6/T9+bZh7UZEAEfTvFl0aTuB8b2Ez2TAOBtQ+3zga2V6GXDEgNpB246RY2xQbZsxNqR25BgbUtt2fA3bXg4dYxu4rR1UO3KMjWp32BgbUtt2fA2qHznGhry/7A9cVJYPGl99azPz+sy8vV9fW9ReXq5L4FoGbMOG1P8YHnu8n0qfcTKoNiK2Bt5HM7469XvYfW1bG80nDvsDl7SsfRT4eWZ+pywfuB1ZPweUx2fkczyovvSp1XM1IIMcD5yWmb8ot9XlZzdHvi4G5Y8u75E9Hssgbd+f17clBe1+P+PeagM8mSJiNs1//Nd0qNk6mo8c7wOWZWbrWuADNBuOX3So6ZXAVRGxIppf32xrT2AtcF75yOiciNhhAu0fw5AAtL7MXAP8E/CfwN3Ag5l5VcvylcBvR8SzImJ7mv+W9+jYX4DdMvPuMn0PsNsEbmNDvRn4Utei8nHencDrgHd2qJsPrMnMG7u2WZxYPs5bFAMOtRng+TTP2TUR8e8R8RsTaPu3gXsz87aOdScB7yuP1z/R/JBWWzfz+D/6R9FinK237eg0xiay3WlRO3KMrV/bdXz11ncdY3363XqMrVfbaYwNeLxajbH1ak+i4/har77VGFv//YXmk98HegLJwPfKDXlvGlZbDkN4A3BF1/qIOI/mNfFC4MMdak8Elva8rrr2+z1lfJ0ZEdt1vc80Qffq9f4hHVhLE25n9BzCcCSDtyMf4Ik54Fm0fI4H1Pf2a9Rz1a/2l4E/KId+fCki5gyo7Zc/TmL066JN/mj7Htkpg/SzJQXtKRfN8WJLgJMGvZj6ycxHM3Nvmv++9o2IX23Z3qHAfZm5YiL9LV6emfsABwMnRMQrWtbNoPm4/KzMfAnwXzQfcbcWzTFjhwGf71CzE82by57Ac4AdIuL1bWozcxXNx0lX0Ww0bqDZazBh5b/91p9ATIaI+GvgEeDTXWsz868zc49Se2LL9rYH/ooOwXw9Z9FsePem+efonzvUzgB2pvn49s+BC8vemi5ey8Q2pMcD7yiP1zsoe09aejPwRxGxgubj/p8PW3nYtmPUGJvodmdYbZsx1q+2y/jqrS9ttR5jfdpuPcb61LYeY0Me65FjrE9tp/HVp77VGFv//YUmoLYy0femFrUfBb6Wmf/RtT4zj6XZ9q8C/qBl7Sto/hnpG8xbtHsKzeP2GzRj5S8ncJ+HjpE+z9OLaELgmRFxLfAT+rxfbWgOaFE/8LkaUrsd8LPMnAv8C7BowG33yx9tXhdD80fb98iJZJC+suUxJtP9wiT8jDvNcWedj9EutdvQHFv4Jxt4P95Ji+NZy7r/QPOf6u00/+E/BHxqA9p+V4e2nw3c3jP/28AXO7Y3H7iqY81RwLk9828EPjrB+/v3wB91HRfArcDuZXp34NauY4oWx4D1qwXeBHwd2L5rv9e77rnDxnpvLfDfafay3F4uj9B8ovDsCbQ79DXW57G+AvjdnvnvAmMdHq8ZwL3ArAk8zw/CY6dIDeDHE3ysnw9cO6T2SduOtmOsX23bMTaots0YG9Zuy/H1hPouY6xF28Oei36PdasxNuTxGjnGBrTbZXyNus9Dx1jPeu+k+Wfihzx+LOsT3jtH1P5Zz/zttPx+T28tcCrN4RNbtant13ZZ9gpafC+p1J5K8x45Pr5+QXOo6UTafWWHdsfv8y7Aj4CnbMD9PRC4sM+6/XLAp9s+xwPqP9XmuRpUC3wb2LNnbD/Y4j6/C/izNq8LhuQPur1H9s0geIz2QFP2M+5l78e5wKrMfH/H2rEo34yNiKcCv08zSEfKzFMyc1Zmzqa5v1/OzFZ7d0t7O0TE08enaV7Irc66kpn3AHdGxAvKogOAW9q2XUxkT+N/AvtFxPblcT+AZs9GKxGxa/n7XJrjsz/TsX1oxtWCMr0AuHQCt9FZRMyj+YjusMx8aAL1vR/fzaf9OPtWZu6ambPLWLuL5stZ97Rsd/ee2VfTcowVl9B8WY2IeD7Nl15+2KH+94BvZ+ZdHWrG/QD4nTK9P9D60JOecbYV8Dc0X0bqt96gbcfIMbaB252+tW3G2JDaVuOrX33bMTak7ZFjbMjjdQkjxtiIx3roGBtS22p8DbnPI8fYgPeXVcBXaA5FgMHja8LvTYNqI+ItwEHAa7Mcv9uh/taIeF7PY3JYv/4MqF2Rmc/uGV8PZebzOvR79552D6f/+Br2eB1JE85/1vHxGn+Ot6PZi/6k53hADngdLZ7jIfWvb/NcDckgl1BeUzRj/Dvr1w7JHyNfF4PyxwTeIyf6aeeTOrTFXGiOuf0OzR6Jv+5Y+1majxz/H81GfuC3e/vUvpzmo92baA5HuAE4pGXtrwHXl9qVDDkzwojbeSUdzzpCc4aWG8vl5gk8ZnsDy0vfLwF26lC7A81/+M+cwH19N80GbCXNN8i361D7HzT/ENwIHDCRcUFz/NvVNBuAfwN27lD76jL9MM1esEF7GfrVrqb5HsL4GOt7Voch9UvKY3YT8K80X2Dr/Fpg+NkG+rX7SeBbpd2llD21LWu3pdlDshL4JrB/lz7TnC3gDyf4PL8cWFHGyjXAr3eofTvNtug7wBmUPTR9avtuO9qMsSG1I8fYkNqRY2xIbdvxNXJ7OWiMDWl75BgbUjtyjA3rMyPG2JB2246vQfUjxxgD3l9otv3Xluf78/TZhg6p/WOa8fUITSg6p0PtIzTvz+P3o+/7Xb96mkNh/095nlfS7LV9Rtu211tn0FlHBvX7yz3tfopyhpC27dLsIZ03ZIwMavd9NP8Y3UpzyNCo7dgrefzMHyOf4xH1rZ6rAbU7Al8sj9nXgRf3Wb9v/qD962Jv1ssfdHuPfFIGoeX78/oXfxlSkiRJqmBLOnREkiRJ2mgM2pIkSVIFBm1JkiSpAoO2JEmSVIFBW5IkSarAoC1JW5CI+OlU90GSthQGbUmSJKkCg7YkbaEi4s8j4rqIuCki3l2WzY6IVRHxLxFxc0RcVX6NTpLUkUFbkrZAEXEgMAfYl+ZX1H49Il5Rrp4DfCQzXwQ8ABwxFX2UpOluxlR3QJI0JQ4sl+vL/NNoAvZ/At/PzBvK8hXA7I3dOUnaHBi0JWnLFMA/ZObHn7AwYjbwcM+iRwEPHZGkCfDQEUnaMl0JvDkingYQETMjYtcp7pMkbVbcoy1JW6DMvCoifgX4ekQA/BR4Pc0ebEnSJIjMnOo+SJIkSZsdDx2RJEmSKjBoS5IkSRUYtCVJkqQKDNqSJElSBQZtSZIkqQKDtiRJklSBQVuSJEmqwKAtSZIkVfD/AX9rctrBMO7YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(x=df['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51123.000000</td>\n",
       "      <td>51123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.689533</td>\n",
       "      <td>9.868533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.576629</td>\n",
       "      <td>3.042034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label           len\n",
       "count  51123.000000  51123.000000\n",
       "mean       7.689533      9.868533\n",
       "std        5.576629      3.042034\n",
       "min        0.000000      2.000000\n",
       "25%        3.000000      8.000000\n",
       "50%        6.000000     10.000000\n",
       "75%       13.000000     12.000000\n",
       "max       18.000000     15.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_idx = (df['len'] <= max_len)\n",
    "df = df[filter_idx]\n",
    "filter_idx = (df['len'] >= min_len)\n",
    "df = df[filter_idx]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Universal Sentence Encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
    "univ_model = hub.load(module_url)\n",
    "# univ_model = hub.load('models/use-4')\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66017cbd6bf463da52f4289b96673e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['sent'] = df['tweet'].progress_apply(lambda x: np.array(univ_model([x])).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(data):\n",
    "    \n",
    "    emb_data = []\n",
    "    for word in data:\n",
    "        if word not in emb_model.key_to_index:\n",
    "            pass\n",
    "        else:\n",
    "            word_emb = emb_model[word] \n",
    "            emb_data.append(word_emb)\n",
    "        \n",
    "    # check if padding / clipping required\n",
    "    pad = False\n",
    "    clip = False\n",
    "    if len(emb_data) < max_pad_len:\n",
    "        pad = True\n",
    "    elif len(emb_data) > max_pad_len:\n",
    "        clip = True\n",
    "    else:\n",
    "        pad = clip = False\n",
    "        \n",
    "    # padding\n",
    "    if pad:\n",
    "        deficiency = max_pad_len - len(emb_data)\n",
    "        for pad in range(deficiency):\n",
    "            emb_data.append(np.zeros(embed_dim))\n",
    "            \n",
    "    elif clip:\n",
    "        # Taking last few tokens\n",
    "        surplus = len(emb_data) - max_pad_len\n",
    "        emb_data = emb_data[(-max_pad_len):]\n",
    "      \n",
    "    emb_data = np.array(emb_data, dtype=float)\n",
    "    # print(emb_data.shape, emb_data.shape==(max_pad_len, embed_dim))\n",
    "    \n",
    "    return emb_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466c3d135cb243408bd8307bc3155477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['emb_matrix'] = df['token'].progress_apply(add_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a1f380e8bb40919149d8b6a78ff14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['emb_flatten'] = df['emb_matrix'].progress_apply(lambda x: x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "      <th>len</th>\n",
       "      <th>sent</th>\n",
       "      <th>emb_matrix</th>\n",
       "      <th>emb_flatten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>village weather pink files figures false claim...</td>\n",
       "      <td>12</td>\n",
       "      <td>[village, weather, pink, files, figures, false...</td>\n",
       "      <td>8</td>\n",
       "      <td>[-0.0069425404, -0.0295896, -0.006452186, -0.0...</td>\n",
       "      <td>[[-0.41749998927116394, 0.17784999310970306, -...</td>\n",
       "      <td>[-0.41749998927116394, 0.17784999310970306, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well terimerikhani stone heart bring two live ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[well, terimerikhani, stone, heart, bring, two...</td>\n",
       "      <td>8</td>\n",
       "      <td>[-0.025012827, -0.08055329, -0.053520076, 0.03...</td>\n",
       "      <td>[[0.12577000260353088, -0.14082999527454376, 0...</td>\n",
       "      <td>[0.12577000260353088, -0.14082999527454376, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>care scorching sun greenery smelling skeletons...</td>\n",
       "      <td>6</td>\n",
       "      <td>[care, scorching, sun, greenery, smelling, ske...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.036358852, 0.036733188, -0.00204817, -0.052...</td>\n",
       "      <td>[[-0.3751699924468994, 0.37608999013900757, -0...</td>\n",
       "      <td>[-0.3751699924468994, 0.37608999013900757, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worship also chanting become good anyone also</td>\n",
       "      <td>4</td>\n",
       "      <td>[worship, also, chanting, become, good, anyone...</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.032048568, 0.011390642, 0.041787915, -0.022...</td>\n",
       "      <td>[[-0.22492000460624695, 0.4537299871444702, 0....</td>\n",
       "      <td>[-0.22492000460624695, 0.4537299871444702, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commit sins</td>\n",
       "      <td>0</td>\n",
       "      <td>[commit, sins]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.033297304, -0.054342553, 0.054994293, -0.0...</td>\n",
       "      <td>[[-0.009603800252079964, 0.07949800044298172, ...</td>\n",
       "      <td>[-0.009603800252079964, 0.07949800044298172, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  \\\n",
       "0  village weather pink files figures false claim...     12   \n",
       "1  well terimerikhani stone heart bring two live ...      7   \n",
       "3  care scorching sun greenery smelling skeletons...      6   \n",
       "5      worship also chanting become good anyone also      4   \n",
       "6                                        commit sins      0   \n",
       "\n",
       "                                               token  len  \\\n",
       "0  [village, weather, pink, files, figures, false...    8   \n",
       "1  [well, terimerikhani, stone, heart, bring, two...    8   \n",
       "3  [care, scorching, sun, greenery, smelling, ske...    8   \n",
       "5  [worship, also, chanting, become, good, anyone...    7   \n",
       "6                                     [commit, sins]    2   \n",
       "\n",
       "                                                sent  \\\n",
       "0  [-0.0069425404, -0.0295896, -0.006452186, -0.0...   \n",
       "1  [-0.025012827, -0.08055329, -0.053520076, 0.03...   \n",
       "3  [0.036358852, 0.036733188, -0.00204817, -0.052...   \n",
       "5  [0.032048568, 0.011390642, 0.041787915, -0.022...   \n",
       "6  [-0.033297304, -0.054342553, 0.054994293, -0.0...   \n",
       "\n",
       "                                          emb_matrix  \\\n",
       "0  [[-0.41749998927116394, 0.17784999310970306, -...   \n",
       "1  [[0.12577000260353088, -0.14082999527454376, 0...   \n",
       "3  [[-0.3751699924468994, 0.37608999013900757, -0...   \n",
       "5  [[-0.22492000460624695, 0.4537299871444702, 0....   \n",
       "6  [[-0.009603800252079964, 0.07949800044298172, ...   \n",
       "\n",
       "                                         emb_flatten  \n",
       "0  [-0.41749998927116394, 0.17784999310970306, -0...  \n",
       "1  [0.12577000260353088, -0.14082999527454376, 0....  \n",
       "3  [-0.3751699924468994, 0.37608999013900757, -0....  \n",
       "5  [-0.22492000460624695, 0.4537299871444702, 0.5...  \n",
       "6  [-0.009603800252079964, 0.07949800044298172, -...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51123, 2000)\n",
      "(51123, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((51123, 2512), (51123,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tok = np.array(list(df['emb_flatten'].to_numpy()))\n",
    "print(X_tok.shape)\n",
    "X_sent = np.array(list(df['sent'].to_numpy()))\n",
    "print(X_sent.shape)\n",
    "\n",
    "X = np.concatenate((X_tok, X_sent), axis=1)\n",
    "y = df['label'].values\n",
    "# y = to_categorical(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46010, 2512) (5113, 2512) (46010, 19) (5113, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EmojiPred Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51123, 2512), (51123,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Input, Bidirectional, Embedding, Dense, Dropout, SpatialDropout1D, LSTM, Activation, GlobalMaxPool1D, Conv1D\n",
    "from keras.regularizers import L1L2\n",
    "from attention import AttentionWeightedAverage\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from os.path import exists\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix issue: add attention!!!\n",
    "### It will take dim from T x 1024 to 1 x 2304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_pred(input_dim, num_classes):\n",
    "    # create model\n",
    "    model_input = Input(shape=input_dim)\n",
    "    \n",
    "    token = model_input[:,:2000]\n",
    "    print(token.shape)\n",
    "    token = tf.reshape(token, [tf.shape(token)[0], 10,200])\n",
    "    sent = model_input[:,-512:]\n",
    "    print(token.shape, sent.shape)\n",
    "    \n",
    "    x = Activation('relu')(token)\n",
    "    # x = Activation('relu')(token)\n",
    "    print(x.shape)\n",
    "    embed_drop = SpatialDropout1D(0.2, name='embed_drop')\n",
    "    x = embed_drop(x)\n",
    "    \n",
    "    # token embeddings are 200, sentence embeddings = 2000\n",
    "    lstm_0_output = Bidirectional(LSTM(400, return_sequences=True), name=\"bi_lstm_0\")(x)\n",
    "    print(x.shape)\n",
    "    lstm_1_output = Bidirectional(LSTM(400, return_sequences=True), name=\"bi_lstm_1\")(lstm_0_output)\n",
    "    print(x.shape)\n",
    "    x = concatenate([lstm_1_output, lstm_0_output, x])\n",
    "    print(x.shape)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    print(x.shape)\n",
    "    # x = AttentionWeightedAverage(name='attlayer', return_attention=False)(x)\n",
    "    \n",
    "    # Concatenate sentence embeddings\n",
    "    sent = Dense(200, activation='relu', name='FC-1')(sent)\n",
    "    print(sent.shape)\n",
    "    x = concatenate([x, sent])\n",
    "    print(x.shape)\n",
    "    outputs = [Dense(num_classes, activation='softmax', name='softmax')(x)]\n",
    "    # print(outputs.shape)\n",
    "    \n",
    "    model = Model(inputs=[model_input], outputs=outputs, name=\"EmojiPredHindi\")\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2000)\n",
      "(None, 10, 200) (None, 512)\n",
      "(None, 10, 200)\n",
      "(None, 10, 200)\n",
      "(None, 10, 200)\n",
      "(None, 10, 1800)\n",
      "(None, 1800)\n",
      "(None, 200)\n",
      "(None, 2000)\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 04:01:18.112490: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295/1295 - 20s - loss: 2.6307 - accuracy: 0.1312 - val_loss: 2.5781 - val_accuracy: 0.1487\n",
      "Epoch 2/5\n",
      "1295/1295 - 14s - loss: 2.5372 - accuracy: 0.1624 - val_loss: 2.5451 - val_accuracy: 0.1734\n",
      "Epoch 3/5\n",
      "1295/1295 - 14s - loss: 2.4815 - accuracy: 0.1812 - val_loss: 2.5609 - val_accuracy: 0.1621\n",
      "Epoch 4/5\n",
      "1295/1295 - 14s - loss: 2.4242 - accuracy: 0.2011 - val_loss: 2.5598 - val_accuracy: 0.1597\n",
      "Epoch 5/5\n",
      "1295/1295 - 14s - loss: 2.3475 - accuracy: 0.2318 - val_loss: 2.5830 - val_accuracy: 0.1663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.23      0.22       377\n",
      "           1       0.19      0.17      0.18       373\n",
      "           2       0.16      0.56      0.25       441\n",
      "           3       0.17      0.37      0.23       330\n",
      "           4       0.37      0.28      0.32       196\n",
      "           5       0.18      0.13      0.15       458\n",
      "           6       0.14      0.18      0.16       477\n",
      "           7       0.15      0.20      0.17       260\n",
      "           8       0.15      0.11      0.13       171\n",
      "           9       0.16      0.04      0.06       276\n",
      "          10       0.31      0.10      0.15       103\n",
      "          11       0.24      0.27      0.25       131\n",
      "          12       0.00      0.00      0.00       146\n",
      "          13       0.15      0.03      0.04       343\n",
      "          14       0.16      0.03      0.06       144\n",
      "          15       0.10      0.02      0.04       400\n",
      "          16       0.38      0.13      0.19        79\n",
      "          17       0.33      0.05      0.09        19\n",
      "          18       0.17      0.01      0.01       389\n",
      "\n",
      "    accuracy                           0.17      5113\n",
      "   macro avg       0.20      0.15      0.14      5113\n",
      "weighted avg       0.17      0.17      0.14      5113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call model\n",
    "mlp_model = emoji_pred((2512,), num_classes)\n",
    "history = mlp_model.fit(X_train, y_train, validation_split=0.1, epochs=5, verbose=2)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cat = mlp_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_cat, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "# result = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "# model_accuracy = result[1]\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "# model_precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "# model_recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "# model_f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# print(f\">>> Accuracy of model = {(100*model_accuracy):.4f} %\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "result = mlp_model.evaluate(X_train, y_train, verbose=0)\n",
    "model_accuracy = result[1]\n",
    "print(model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46010, 2512), (46010, 19))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 accuracy\n",
    "If any of model's top-5 predictions matches with the correct result, set 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_acc(y_test, y_pred_cat):\n",
    "    n = y_pred_cat.shape[0]\n",
    "    plen = y_pred_cat.shape[1]\n",
    "    top_5 = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        true_val = y_test[i]\n",
    "        pred_prob = y_pred_cat[i]\n",
    "        pred_prob = [(pred_prob[j], j) for j in range(plen)]\n",
    "        pred_prob = sorted(pred_prob)[::-1]\n",
    "        pred_prob = pred_prob[:5]\n",
    "        pred_labels = [k[1] for k in pred_prob]\n",
    "        # print(pred_labels)\n",
    "        if true_val in pred_labels:\n",
    "            top_5[i] = 1\n",
    "    \n",
    "    return np.mean(top_5)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy of model = 58.7326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top-5 accuracy of model = {top_5_acc(y_test, y_pred_cat):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.save('models/emoji_pred_hindi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_pred_conv(input_dim, num_classes):\n",
    "    # create model\n",
    "    model_input = Input(shape=input_dim)\n",
    "    x = Activation('relu')(model_input)\n",
    "    print(x.shape)\n",
    "    embed_drop = SpatialDropout1D(0.2, name='embed_drop')\n",
    "    x = embed_drop(x)\n",
    "    \n",
    "    conv_1 = Conv1D(512, 3, dilation_rate = [1], padding='causal', activation='relu',name = 'conv_1')(x)\n",
    "    print(x.shape)\n",
    "    conv_2 = Conv1D(256, 3, dilation_rate = [2], padding='causal', activation = 'relu',name = 'conv_2')(conv_1)\n",
    "    print(x.shape)\n",
    "    conv_3 = Conv1D(128, 3, dilation_rate = [3], padding='causal', activation = 'relu',name = 'conv_3')(conv_2)\n",
    "    print(x.shape)\n",
    "    \n",
    "    # # token embeddings are 200, sentence embeddings = 2000\n",
    "    # lstm_0_output = Bidirectional(LSTM(400, return_sequences=True), name=\"bi_lstm_0\")(x)\n",
    "    # print(x.shape)\n",
    "    # lstm_1_output = Bidirectional(LSTM(400, return_sequences=True), name=\"bi_lstm_1\")(lstm_0_output)\n",
    "    # print(x.shape)\n",
    "    # x = concatenate([lstm_1_output, lstm_0_output, x])\n",
    "    x = concatenate([conv_3, conv_2, conv_1, x])\n",
    "    print(x.shape)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    print(x.shape)\n",
    "    # x = AttentionWeightedAverage(name='attlayer', return_attention=False)(x)\n",
    "    outputs = [Dense(num_classes, activation='softmax', name='softmax')(x)]\n",
    "    # print(outputs.shape)\n",
    "    \n",
    "    model = Model(inputs=[model_input], outputs=outputs, name=\"EmojiPredConv\")\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 200)\n",
      "(None, 10, 200)\n",
      "(None, 10, 200)\n",
      "(None, 10, 200)\n",
      "(None, 10, 1096)\n",
      "(None, 1096)\n",
      "Epoch 1/100\n",
      "1962/1962 - 13s - loss: 2.4596 - accuracy: 0.2830 - val_loss: 2.3376 - val_accuracy: 0.3072\n",
      "Epoch 2/100\n",
      "1962/1962 - 12s - loss: 2.3131 - accuracy: 0.3199 - val_loss: 2.2464 - val_accuracy: 0.3342\n",
      "Epoch 3/100\n",
      "1962/1962 - 12s - loss: 2.2375 - accuracy: 0.3381 - val_loss: 2.1949 - val_accuracy: 0.3459\n",
      "Epoch 4/100\n",
      "1962/1962 - 12s - loss: 2.1626 - accuracy: 0.3546 - val_loss: 2.1277 - val_accuracy: 0.3591\n",
      "Epoch 5/100\n",
      "1962/1962 - 12s - loss: 2.0821 - accuracy: 0.3714 - val_loss: 2.0782 - val_accuracy: 0.3732\n",
      "Epoch 6/100\n",
      "1962/1962 - 12s - loss: 1.9861 - accuracy: 0.3960 - val_loss: 2.0048 - val_accuracy: 0.3890\n",
      "Epoch 7/100\n",
      "1962/1962 - 12s - loss: 1.8893 - accuracy: 0.4193 - val_loss: 1.9704 - val_accuracy: 0.4043\n",
      "Epoch 8/100\n",
      "1962/1962 - 12s - loss: 1.7957 - accuracy: 0.4428 - val_loss: 1.9057 - val_accuracy: 0.4239\n",
      "Epoch 9/100\n",
      "1962/1962 - 12s - loss: 1.6988 - accuracy: 0.4721 - val_loss: 1.8610 - val_accuracy: 0.4409\n",
      "Epoch 10/100\n",
      "1962/1962 - 12s - loss: 1.6119 - accuracy: 0.4935 - val_loss: 1.8192 - val_accuracy: 0.4552\n",
      "Epoch 11/100\n",
      "1962/1962 - 12s - loss: 1.5303 - accuracy: 0.5203 - val_loss: 1.8109 - val_accuracy: 0.4677\n",
      "Epoch 12/100\n",
      "1962/1962 - 12s - loss: 1.4589 - accuracy: 0.5385 - val_loss: 1.7565 - val_accuracy: 0.4859\n",
      "Epoch 13/100\n",
      "1962/1962 - 12s - loss: 1.3849 - accuracy: 0.5609 - val_loss: 1.7622 - val_accuracy: 0.4926\n",
      "Epoch 14/100\n",
      "1962/1962 - 12s - loss: 1.3266 - accuracy: 0.5773 - val_loss: 1.7607 - val_accuracy: 0.4984\n",
      "Epoch 15/100\n",
      "1962/1962 - 12s - loss: 1.2722 - accuracy: 0.5925 - val_loss: 1.7449 - val_accuracy: 0.5163\n",
      "Epoch 16/100\n",
      "1962/1962 - 12s - loss: 1.2145 - accuracy: 0.6089 - val_loss: 1.7303 - val_accuracy: 0.5148\n",
      "Epoch 17/100\n",
      "1962/1962 - 12s - loss: 1.1696 - accuracy: 0.6237 - val_loss: 1.7725 - val_accuracy: 0.5191\n",
      "Epoch 18/100\n",
      "1962/1962 - 12s - loss: 1.1351 - accuracy: 0.6346 - val_loss: 1.7622 - val_accuracy: 0.5236\n",
      "Epoch 19/100\n",
      "1962/1962 - 12s - loss: 1.0818 - accuracy: 0.6516 - val_loss: 1.7565 - val_accuracy: 0.5323\n",
      "Epoch 20/100\n",
      "1962/1962 - 12s - loss: 1.0561 - accuracy: 0.6576 - val_loss: 1.7588 - val_accuracy: 0.5451\n",
      "Epoch 21/100\n",
      "1962/1962 - 12s - loss: 1.0261 - accuracy: 0.6683 - val_loss: 1.7449 - val_accuracy: 0.5583\n",
      "Epoch 22/100\n",
      "1962/1962 - 12s - loss: 0.9873 - accuracy: 0.6812 - val_loss: 1.7965 - val_accuracy: 0.5445\n",
      "Epoch 23/100\n",
      "1962/1962 - 12s - loss: 0.9651 - accuracy: 0.6877 - val_loss: 1.7964 - val_accuracy: 0.5578\n",
      "Epoch 24/100\n",
      "1962/1962 - 12s - loss: 0.9351 - accuracy: 0.6971 - val_loss: 1.8071 - val_accuracy: 0.5587\n",
      "Epoch 25/100\n",
      "1962/1962 - 12s - loss: 0.9158 - accuracy: 0.7026 - val_loss: 1.8738 - val_accuracy: 0.5564\n",
      "Epoch 26/100\n",
      "1962/1962 - 12s - loss: 0.9013 - accuracy: 0.7082 - val_loss: 1.8678 - val_accuracy: 0.5507\n",
      "Epoch 27/100\n",
      "1962/1962 - 12s - loss: 0.8827 - accuracy: 0.7136 - val_loss: 1.8689 - val_accuracy: 0.5576\n",
      "Epoch 28/100\n",
      "1962/1962 - 12s - loss: 0.8530 - accuracy: 0.7249 - val_loss: 1.8628 - val_accuracy: 0.5609\n",
      "Epoch 29/100\n",
      "1962/1962 - 12s - loss: 0.8343 - accuracy: 0.7299 - val_loss: 1.9783 - val_accuracy: 0.5503\n",
      "Epoch 30/100\n",
      "1962/1962 - 12s - loss: 0.8229 - accuracy: 0.7335 - val_loss: 1.9433 - val_accuracy: 0.5634\n",
      "Epoch 31/100\n",
      "1962/1962 - 12s - loss: 0.8071 - accuracy: 0.7392 - val_loss: 1.9303 - val_accuracy: 0.5665\n",
      "Epoch 32/100\n",
      "1962/1962 - 12s - loss: 0.8000 - accuracy: 0.7438 - val_loss: 1.9491 - val_accuracy: 0.5699\n",
      "Epoch 33/100\n",
      "1962/1962 - 12s - loss: 0.7838 - accuracy: 0.7472 - val_loss: 1.9835 - val_accuracy: 0.5639\n",
      "Epoch 34/100\n",
      "1962/1962 - 12s - loss: 0.7648 - accuracy: 0.7540 - val_loss: 1.9670 - val_accuracy: 0.5795\n",
      "Epoch 35/100\n",
      "1962/1962 - 12s - loss: 0.7647 - accuracy: 0.7561 - val_loss: 2.0371 - val_accuracy: 0.5623\n",
      "Epoch 36/100\n",
      "1962/1962 - 12s - loss: 0.7449 - accuracy: 0.7615 - val_loss: 2.0139 - val_accuracy: 0.5742\n",
      "Epoch 37/100\n",
      "1962/1962 - 12s - loss: 0.7405 - accuracy: 0.7643 - val_loss: 2.0283 - val_accuracy: 0.5804\n",
      "Epoch 38/100\n",
      "1962/1962 - 12s - loss: 0.7342 - accuracy: 0.7678 - val_loss: 2.0458 - val_accuracy: 0.5814\n",
      "Epoch 39/100\n",
      "1962/1962 - 12s - loss: 0.7214 - accuracy: 0.7713 - val_loss: 2.0937 - val_accuracy: 0.5709\n",
      "Epoch 40/100\n",
      "1962/1962 - 12s - loss: 0.7037 - accuracy: 0.7771 - val_loss: 2.1046 - val_accuracy: 0.5816\n",
      "Epoch 41/100\n",
      "1962/1962 - 12s - loss: 0.7051 - accuracy: 0.7761 - val_loss: 2.0834 - val_accuracy: 0.5865\n",
      "Epoch 42/100\n",
      "1962/1962 - 12s - loss: 0.6871 - accuracy: 0.7820 - val_loss: 2.1263 - val_accuracy: 0.5808\n",
      "Epoch 43/100\n",
      "1962/1962 - 12s - loss: 0.6889 - accuracy: 0.7824 - val_loss: 2.1039 - val_accuracy: 0.5871\n",
      "Epoch 44/100\n",
      "1962/1962 - 12s - loss: 0.6785 - accuracy: 0.7843 - val_loss: 2.1410 - val_accuracy: 0.5845\n",
      "Epoch 45/100\n",
      "1962/1962 - 12s - loss: 0.6674 - accuracy: 0.7884 - val_loss: 2.1280 - val_accuracy: 0.5786\n",
      "Epoch 46/100\n",
      "1962/1962 - 12s - loss: 0.6654 - accuracy: 0.7903 - val_loss: 2.1877 - val_accuracy: 0.5878\n",
      "Epoch 47/100\n",
      "1962/1962 - 12s - loss: 0.6511 - accuracy: 0.7971 - val_loss: 2.1940 - val_accuracy: 0.5824\n",
      "Epoch 48/100\n",
      "1962/1962 - 12s - loss: 0.6533 - accuracy: 0.7951 - val_loss: 2.2446 - val_accuracy: 0.5890\n",
      "Epoch 49/100\n",
      "1962/1962 - 12s - loss: 0.6397 - accuracy: 0.7994 - val_loss: 2.2120 - val_accuracy: 0.5828\n",
      "Epoch 50/100\n",
      "1962/1962 - 12s - loss: 0.6363 - accuracy: 0.8011 - val_loss: 2.2647 - val_accuracy: 0.5821\n",
      "Epoch 51/100\n",
      "1962/1962 - 12s - loss: 0.6243 - accuracy: 0.8027 - val_loss: 2.2340 - val_accuracy: 0.5824\n",
      "Epoch 52/100\n",
      "1962/1962 - 12s - loss: 0.6248 - accuracy: 0.8064 - val_loss: 2.2559 - val_accuracy: 0.5824\n",
      "Epoch 53/100\n",
      "1962/1962 - 12s - loss: 0.6200 - accuracy: 0.8057 - val_loss: 2.2550 - val_accuracy: 0.5924\n",
      "Epoch 54/100\n",
      "1962/1962 - 12s - loss: 0.6120 - accuracy: 0.8085 - val_loss: 2.2853 - val_accuracy: 0.5913\n",
      "Epoch 55/100\n",
      "1962/1962 - 12s - loss: 0.6084 - accuracy: 0.8116 - val_loss: 2.2578 - val_accuracy: 0.5897\n",
      "Epoch 56/100\n",
      "1962/1962 - 12s - loss: 0.6053 - accuracy: 0.8113 - val_loss: 2.3139 - val_accuracy: 0.5930\n",
      "Epoch 57/100\n",
      "1962/1962 - 12s - loss: 0.6067 - accuracy: 0.8124 - val_loss: 2.3257 - val_accuracy: 0.5917\n",
      "Epoch 58/100\n",
      "1962/1962 - 12s - loss: 0.5961 - accuracy: 0.8159 - val_loss: 2.2976 - val_accuracy: 0.5997\n",
      "Epoch 59/100\n",
      "1962/1962 - 12s - loss: 0.5842 - accuracy: 0.8216 - val_loss: 2.3755 - val_accuracy: 0.5940\n",
      "Epoch 60/100\n",
      "1962/1962 - 12s - loss: 0.5882 - accuracy: 0.8190 - val_loss: 2.4149 - val_accuracy: 0.5835\n",
      "Epoch 61/100\n",
      "1962/1962 - 12s - loss: 0.5920 - accuracy: 0.8192 - val_loss: 2.4291 - val_accuracy: 0.5913\n",
      "Epoch 62/100\n",
      "1962/1962 - 12s - loss: 0.5799 - accuracy: 0.8228 - val_loss: 2.3754 - val_accuracy: 0.5917\n",
      "Epoch 63/100\n",
      "1962/1962 - 12s - loss: 0.5775 - accuracy: 0.8242 - val_loss: 2.4340 - val_accuracy: 0.5872\n",
      "Epoch 64/100\n",
      "1962/1962 - 12s - loss: 0.5726 - accuracy: 0.8245 - val_loss: 2.4644 - val_accuracy: 0.5950\n",
      "Epoch 65/100\n",
      "1962/1962 - 12s - loss: 0.5732 - accuracy: 0.8266 - val_loss: 2.3904 - val_accuracy: 0.5981\n",
      "Epoch 66/100\n",
      "1962/1962 - 12s - loss: 0.5716 - accuracy: 0.8280 - val_loss: 2.3984 - val_accuracy: 0.5904\n",
      "Epoch 67/100\n",
      "1962/1962 - 12s - loss: 0.5680 - accuracy: 0.8273 - val_loss: 2.4420 - val_accuracy: 0.5970\n",
      "Epoch 68/100\n",
      "1962/1962 - 12s - loss: 0.5577 - accuracy: 0.8318 - val_loss: 2.4574 - val_accuracy: 0.5818\n",
      "Epoch 69/100\n",
      "1962/1962 - 12s - loss: 0.5588 - accuracy: 0.8299 - val_loss: 2.4686 - val_accuracy: 0.5993\n",
      "Epoch 70/100\n",
      "1962/1962 - 12s - loss: 0.5579 - accuracy: 0.8322 - val_loss: 2.4284 - val_accuracy: 0.5940\n",
      "Epoch 71/100\n",
      "1962/1962 - 12s - loss: 0.5563 - accuracy: 0.8330 - val_loss: 2.4184 - val_accuracy: 0.6003\n",
      "Epoch 72/100\n",
      "1962/1962 - 12s - loss: 0.5444 - accuracy: 0.8367 - val_loss: 2.5115 - val_accuracy: 0.5871\n",
      "Epoch 73/100\n",
      "1962/1962 - 12s - loss: 0.5552 - accuracy: 0.8334 - val_loss: 2.4927 - val_accuracy: 0.5984\n",
      "Epoch 74/100\n",
      "1962/1962 - 12s - loss: 0.5478 - accuracy: 0.8371 - val_loss: 2.4764 - val_accuracy: 0.6044\n",
      "Epoch 75/100\n",
      "1962/1962 - 12s - loss: 0.5415 - accuracy: 0.8389 - val_loss: 2.4872 - val_accuracy: 0.5983\n",
      "Epoch 76/100\n",
      "1962/1962 - 12s - loss: 0.5407 - accuracy: 0.8403 - val_loss: 2.5167 - val_accuracy: 0.6030\n",
      "Epoch 77/100\n",
      "1962/1962 - 12s - loss: 0.5378 - accuracy: 0.8405 - val_loss: 2.5511 - val_accuracy: 0.6039\n",
      "Epoch 78/100\n",
      "1962/1962 - 12s - loss: 0.5386 - accuracy: 0.8393 - val_loss: 2.5907 - val_accuracy: 0.5940\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24252/3611772600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memoji_pred_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ep/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call model\n",
    "mlp_model = emoji_pred_conv((10,200), num_classes)\n",
    "history = mlp_model.fit(X, y, validation_split=0.1, epochs=100, verbose=2)\n",
    "\n",
    "# Predictions\n",
    "# y_pred_cat = mlp_model.predict(X)\n",
    "# y_pred = np.argmax(y_pred_cat, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "result = mlp_model.evaluate(X, y, verbose=0)\n",
    "model_accuracy = result[1]\n",
    "# y_test = np.argmax(y_test, axis=1)\n",
    "# model_precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "# model_recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "# model_f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\">>> Accuracy of MLP model = {(100*model_accuracy):.4f} %\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement tensorflow model for classification\n",
    "\n",
    "# define classification model\n",
    "def classification_model(input_dim, num_classes):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1962/1962 - 6s - loss: 2.5144 - accuracy: 0.2721 - val_loss: 2.3404 - val_accuracy: 0.2979\n",
      "Epoch 2/10\n",
      "1962/1962 - 5s - loss: 2.3098 - accuracy: 0.3143 - val_loss: 2.2092 - val_accuracy: 0.3297\n",
      "Epoch 3/10\n",
      "1962/1962 - 5s - loss: 2.0977 - accuracy: 0.3616 - val_loss: 2.0612 - val_accuracy: 0.3708\n",
      "Epoch 4/10\n",
      "1962/1962 - 5s - loss: 1.8165 - accuracy: 0.4305 - val_loss: 1.9210 - val_accuracy: 0.4292\n",
      "Epoch 5/10\n",
      "1962/1962 - 5s - loss: 1.5087 - accuracy: 0.5156 - val_loss: 1.8275 - val_accuracy: 0.4748\n",
      "Epoch 6/10\n",
      "1962/1962 - 5s - loss: 1.2279 - accuracy: 0.6006 - val_loss: 1.7778 - val_accuracy: 0.5146\n",
      "Epoch 7/10\n",
      "1962/1962 - 5s - loss: 1.0094 - accuracy: 0.6692 - val_loss: 1.7947 - val_accuracy: 0.5406\n",
      "Epoch 8/10\n",
      "1962/1962 - 5s - loss: 0.8549 - accuracy: 0.7204 - val_loss: 1.8501 - val_accuracy: 0.5557\n",
      "Epoch 9/10\n",
      "1962/1962 - 5s - loss: 0.7362 - accuracy: 0.7608 - val_loss: 1.8747 - val_accuracy: 0.5712\n",
      "Epoch 10/10\n",
      "1962/1962 - 5s - loss: 0.6428 - accuracy: 0.7893 - val_loss: 1.9395 - val_accuracy: 0.5756\n",
      ">>> Accuracy of MLP model = 90.7029 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call model\n",
    "mlp_model = classification_model(2000, num_classes)\n",
    "history = mlp_model.fit(X, y, validation_split=0.1, epochs=1, verbose=2)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cat = mlp_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_cat, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "result = mlp_model.evaluate(X, y, verbose=0)\n",
    "model_accuracy = result[1]\n",
    "# y_test = np.argmax(y_test, axis=1)\n",
    "# model_precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "# model_recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "# model_f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\">>> Accuracy of MLP model = {(100*model_accuracy):.4f} %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
